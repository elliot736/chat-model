{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i'm getting frequent errors when i try to acce...</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>example:i am experiencing slow internet speeds...</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm experiencing slow download speeds on my in...</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my internet connection has been running extrem...</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my internet connection suddenly dropped and i ...</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt       intent\n",
       "0  i'm getting frequent errors when i try to acce...  performance\n",
       "1  example:i am experiencing slow internet speeds...  performance\n",
       "2  i'm experiencing slow download speeds on my in...  performance\n",
       "3  my internet connection has been running extrem...  performance\n",
       "4  my internet connection suddenly dropped and i ...  performance"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('intent_final.csv')\n",
    "# change column name to intent\n",
    "df = df.rename(columns={'error': 'intent'})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "possible_labels = df.intent.unique()\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "df['intent_id'] = df.intent.replace(label_dict)\n",
    "df.head()\n",
    "# print(df1)\n",
    "df.to_csv(\"intent_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m enitity_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39menitity_model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-cased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# preparing the data that will be passed to the model as an input for testing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:622\u001b[0m, in \u001b[0;36mContext.ensure_initialized\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    618\u001b[0m   pywrap_tfe\u001b[39m.\u001b[39mTFE_ContextOptionsSetRunEagerOpAsFunction(\n\u001b[0;32m    619\u001b[0m       opts, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_eager_op_as_function)\n\u001b[0;32m    620\u001b[0m   pywrap_tfe\u001b[39m.\u001b[39mTFE_ContextOptionsSetJitCompileRewrite(\n\u001b[0;32m    621\u001b[0m       opts, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile_rewrite)\n\u001b[1;32m--> 622\u001b[0m   context_handle \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_NewContext(opts)\n\u001b[0;32m    623\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    624\u001b[0m   pywrap_tfe\u001b[39m.\u001b[39mTFE_DeleteContextOptions(opts)\n",
      "\u001b[1;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found."
     ]
    }
   ],
   "source": [
    "enitity_model = tf.keras.models.load_model('enitity_model')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# preparing the data that will be passed to the model as an input for testing\n",
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=32, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        add_special_tokens=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
    "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
    "    }\n",
    "\n",
    "def make_prediction(model, processed_data, classes=['battery', 'printer', 'wifi', 'monitor', 'computer', 'keyboard',\n",
    "       'mouse']):\n",
    "    # The predict method is used to pass the processed_data to the neural network\n",
    "    #  and obtain the predicted class probabilities.\n",
    "    # The result of the predict method is a 2-dimensional array\n",
    "    # the first dimension represents the number of samples in processed_data \n",
    "    # the second dimension represents the number of classes in the output layer.\n",
    "    # The indexing [0] is used to extract the predicted class probabilities\n",
    "    # The np.argmax method is used to extract the index of the class with the highest probability\n",
    "    # The classes map the index to its corresponding class name\n",
    "    probs = model.predict(processed_data)[0]\n",
    "    # returns the class with the highest probability\n",
    "    return classes[np.argmax(probs)]\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
